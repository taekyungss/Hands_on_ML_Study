{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1Hk-OTxHfoaa-oSUlrTKJw1mjHMoSCP6B",
      "authorship_tag": "ABX9TyMKbIFTZliJdygaeYXr6Bp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taekyungss/Hands_on_ML_Study/blob/main/Chapter2_housing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **chapter2. 머신러닝 프로젝트 처음부터 끝까지**"
      ],
      "metadata": {
        "id": "sgCv6nVxAckj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 다운로드"
      ],
      "metadata": {
        "id": "UKdRIK24T9ia"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrC_Z9mnAYe9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/rickiepark/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url = HOUSING_URL, housing_path = HOUSING_PATH):\n",
        "  os.makedirs(housing_path,exist_ok =True)\n",
        "  tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "  urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "  housing_tgz = tarfile.open(tgz_path)\n",
        "  housing_tgz.extractall(path = housing_path)\n",
        "  housing_tgz.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_housing_data()"
      ],
      "metadata": {
        "id": "q91xUDSnWtBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 판다스 사용해 데이터 읽어오기 - 데이터 프레임 객체 반환"
      ],
      "metadata": {
        "id": "EYdCiaAxXz5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path = HOUSING_PATH):\n",
        "  csv_path = os.path.join(housing_path,\"housing.csv\")\n",
        "  return pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "FQQ5JUqxWAeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 구조 흝어보기"
      ],
      "metadata": {
        "id": "YH8xCR0YYEUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# housing 변수에 불러온 데이터 저장, 5행 불러오기.\n",
        "housing = load_housing_data()\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "FRwuLJfxYJab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature는 longitude, longitude housing_median_age total_rooms total_bedrooms~"
      ],
      "metadata": {
        "id": "_A8uOWrSYM1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터에 대한 간단한 설명\n",
        "\n",
        "housing.info()"
      ],
      "metadata": {
        "id": "NcwM539jYipm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ocean_proximity 의 경우, Dtype이 object, 아마 범주형 추정\n",
        "# 어떤 카테고리가 있고 얼마나 많은 구역이 있는지 확인\n",
        "\n",
        "housing[\"ocean_proximity\"].value_counts()\n"
      ],
      "metadata": {
        "id": "bHWfejGTYlEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# descrobe method : 숫자형 특성의 요약 정보 나타냄\n",
        "\n",
        "housing.describe()"
      ],
      "metadata": {
        "id": "X9p6J5ysZPt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자형 데이터에 대해 히스토그램으로 시각화해보기\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "housing.hist(bins=50,figsize=(10,8))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "du_Wb0GjZfL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# housing_median_age , median_house_value feature들을 봤을때, 젤 오른쪽 값이 급격하게 높아지면서 히스토그램이 끝남.\n",
        "# 이는 마지막 값으로 한정 (한계값을 넘어가지 않도록 미리 최댓값을 정해서 설정해놓은것을 알 수 있음. ) 이 부분이 문제가 되는 지 안되는지 검토할 필요가 있음.\n",
        "# 만약 정확한 예측값이 필요한 경우, a. 한곗값 밖의 구역에 대한 정확한 레이블을 구한다. b. 훈련 세트에서 이런 구역을 제거한다. (테스트세트에서도 제거)"
      ],
      "metadata": {
        "id": "MItW5LBijM59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 세트 만들기"
      ],
      "metadata": {
        "id": "0lHW4BALllWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "순수한 무작위 방식"
      ],
      "metadata": {
        "id": "ucTHsCjDjvm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "WtsK4s4wjqc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def split_train_test(data, test_ratio):\n",
        "  shuffled_indices = np.random.permutation(len(data))\n",
        "  test_set_size = int(len(data)*test_ratio)\n",
        "  test_indices = shuffled_indices[:test_set_size]\n",
        "  train_indices = shuffled_indices[test_set_size:]\n",
        "  return data.iloc[train_indices], data.iloc[test_indices]"
      ],
      "metadata": {
        "id": "_A2kAolZlxr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = split_train_test(housing, 0.2)\n",
        "\n",
        "print(len(train_set))\n",
        "print(len(test_set))"
      ],
      "metadata": {
        "id": "f1W2dztTmor1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프로그램을 다시 실행하면 다른 테스트 세트 생성 , \n",
        "# --> 알고리즘이 전체 데이터셋을 볼 수도.. 따라서 기존 훈련과 test를 완벽히 분리해야함.\n",
        "# 이를 구현한 코드\n",
        "import numpy as np\n",
        "\n",
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "  return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test_by_id(data, test_ratio, id_column):\n",
        "  ids = data[id_column]\n",
        "  in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
        "  return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "  \n"
      ],
      "metadata": {
        "id": "N6eecUJEmytg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "def test_set_check(identifier, test_ratio, hash=hashlib.md5):\n",
        "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio"
      ],
      "metadata": {
        "id": "lGN3n6eEleT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_with_id = housing.reset_index()\n",
        "\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
      ],
      "metadata": {
        "id": "7rZ8NvblstSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
      ],
      "metadata": {
        "id": "WHtgRYFYtPop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런을 통해 데이터셋을 train, test로 분리\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set= train_test_split(housing, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0XPBMQhJty7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "계층적 샘플링 방식\n",
        "\n",
        "특정 방식을 유지하면서 샘플 추출"
      ],
      "metadata": {
        "id": "9lQfIJonj0-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전문가들이 중간 소득이 중간 주택 가격을 예측하는데 익어서 매우 중요하다고 한다. \n",
        "# 이 경우, 중간 소득의 비율을 유지하면서 / 즉, 테스트 세트가 전체 데이터셋에 있는 여러 소득 카테고리를 잘 대표해야한다."
      ],
      "metadata": {
        "id": "azn9emFVj24y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"median_income\"].hist()"
      ],
      "metadata": {
        "id": "VyCr5ch9k6zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], \n",
        "                               bins=[0.,1.5,3.0,4.5,6., np.inf], \n",
        "                               labels=[1,2,3,4,5])"
      ],
      "metadata": {
        "id": "hFAaTyHGkSRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"].value_counts()"
      ],
      "metadata": {
        "id": "KeI3FNKblFd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"].hist()"
      ],
      "metadata": {
        "id": "w8h4Oh10lMrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "  strat_train_set = housing.loc[train_index]\n",
        "  strat_test_set = housing.loc[test_index]"
      ],
      "metadata": {
        "id": "v2pIAR5okjg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
      ],
      "metadata": {
        "id": "Au6fe6QvmGaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"].value_counts() / len(housing)"
      ],
      "metadata": {
        "id": "tI0vpCnolklQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"]"
      ],
      "metadata": {
        "id": "0Z5YBxP8mS5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# income_cat특성 삭제, 데이터 원래 상태로 복구\n",
        "\n",
        "for set_ in (strat_train_set, strat_test_set):\n",
        "  set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "6Wg4mjg7mNr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 이해를 위한 탐색과 시각화"
      ],
      "metadata": {
        "id": "iPylFhTbm9JB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련세트 손상 시키지 않기 위해 복사본 만들어 사용\n",
        "\n",
        "housing = strat_train_set.copy()\n",
        "# print(housing)\n",
        "\n",
        "# 특성 및 레이블 분리\n",
        "\n",
        "# housing = strat_train_set.drop(\"median_house_value\", axis = 1)\n",
        "# housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ],
      "metadata": {
        "id": "_9uZPiXBnMZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지리적 데이터 시각화 ( 지리정보 ) --> 산점도\n",
        "\n",
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
        "\n",
        "# alpha 옵션 -> 데이터 포인트가 밀집된 영역을 잘 보여줌."
      ],
      "metadata": {
        "id": "mCp9knr0nXcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "             s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "             c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True, \n",
        "             sharex=False\n",
        "             )\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "64qcZpIZnj9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 시각화 그림을 통해 주액 가격은 지역과 인구 밀도에 관련이 크다는 것을 확인 가능."
      ],
      "metadata": {
        "id": "PkShJJOkeUJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 상관관계 조사"
      ],
      "metadata": {
        "id": "yi2FLJP4fXoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 표준 상관계수(피어슨의 r) corr() method 사용\n",
        "\n",
        "corr_matrix = housing.corr()"
      ],
      "metadata": {
        "id": "ShiO55vtfZiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "KTYED5P-fm2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import Attribute\n",
        "# scatter_matrix 함수 사용해서 산점도 그려서 상관관계 확인\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "attributes = [\"median_house_value\",\"median_income\", \"total_rooms\",\"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(8,5))"
      ],
      "metadata": {
        "id": "WK0CNVN4fxYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# median_house_value을 예측하는데 중간소득이 가장 유용 해당 상관관계 산점도\n",
        "\n",
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
        "             alpha=0.1)\n"
      ],
      "metadata": {
        "id": "SfnBzDJagpTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 그래프에서 직선에 가까운 수평선이 잘 보임. 이런 이상한 형태 학습하지 않도록 해당 구역 제거할 필요 있음."
      ],
      "metadata": {
        "id": "4ygeBqiEhMGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 특성 조합으로 실험"
      ],
      "metadata": {
        "id": "UcXzq2UUhevN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.head()"
      ],
      "metadata": {
        "id": "ZBZ6bM_CF8cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"] = housing[\"population\"]/housing[\"households\"]"
      ],
      "metadata": {
        "id": "is50hkWghjZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "0TW_EsKWGb_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
        "             alpha = 0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9sw_LiuPnLUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 정제"
      ],
      "metadata": {
        "id": "eQizkzTgHjHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 알고리즘을 위한 데이터 준비\n",
        "\n",
        "housing = strat_train_set.drop(\"median_house_value\", axis=1) # 훈련 세트를 위해 레이블 삭제\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ],
      "metadata": {
        "id": "nFLE0NYYnaqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.info() # null값 존재 이제 처리"
      ],
      "metadata": {
        "id": "t5TVLhdFHnuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 처리방법 3가지 1. 해당 구역 제거 2. 전체 특성 삭제 3. 어떤 값으로 채우기(0, 평균, 중간값 등.)\n",
        "\n",
        "# housing.dropna(subset=[\"total_bedrooms\"]) # 옵션1\n",
        "# housing.drop(\"total_bedrooms\", axis=1)  # 옵션2\n",
        "# median = housing[\"total_bedrooms\"].median()\n",
        "# housing[\"total_bedrooms\"].fillna(median,inplace=True)  # 옵션3"
      ],
      "metadata": {
        "id": "_lktH9J1H9xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런의 SimpleImputer을 사용해 누락된 값 손쉽게 다루기 _ 중앙값으로 결측지 채우기\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy =\"median\")\n",
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
        "imputer.fit(housing_num)"
      ],
      "metadata": {
        "id": "qFLQuT7LJAjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 어떤 값을 저장했는지 확인\n",
        "imputer.statistics_"
      ],
      "metadata": {
        "id": "WUfXroNMMGT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_num.median().values"
      ],
      "metadata": {
        "id": "YoYFQ7nVMc8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = imputer.transform(housing_num)"
      ],
      "metadata": {
        "id": "-0Pwr2F3Mze1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_tr = pd.DataFrame(X, columns = housing_num.columns,\n",
        "                          index=housing_num.index)"
      ],
      "metadata": {
        "id": "vw0KKo_gM-nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# housing_tr.loc[sample_incomplete_rows.index.values]\n",
        "\n",
        "imputer.strategy\n",
        "housing_tr.head()"
      ],
      "metadata": {
        "id": "8Jmsk7T9nuyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트와 범주형 특성 다루기"
      ],
      "metadata": {
        "id": "quG4YOgseF2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_cat = housing[[\"ocean_proximity\"]]\n",
        "housing_cat.head(10)"
      ],
      "metadata": {
        "id": "MSa54dQHeNft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당 카테고리를 텍스트에서 숫자로 변환\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "metadata": {
        "id": "8uEOsufveUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ordinal_encoder = OrdinalEncoder()\n",
        "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        "housing_cat_encoded[:10]"
      ],
      "metadata": {
        "id": "COyyguWse1zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 카테고리 목록 얻기\n",
        "\n",
        "ordinal_encoder.categories_"
      ],
      "metadata": {
        "id": "1xVpaJVye6zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One_hot encoding\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ],
      "metadata": {
        "id": "NIb_ce11dPII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding 은 사이파이 희소행렬 sparse matrix 수천 개의 카테고리가 있는 범주형 특성일 경우 효율정\n",
        "\n",
        "housing_cat_1hot.toarray()"
      ],
      "metadata": {
        "id": "4guBoM6vdlxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 카테고리 얻기\n",
        "\n",
        "cat_encoder.categories_"
      ],
      "metadata": {
        "id": "OiPHCDnlrtPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 나만의 변환기 만들기"
      ],
      "metadata": {
        "id": "a0_sT5H2tIRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# 열 인덱스\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3,4,5,6\n",
        "\n",
        "class CombinedAttributeAdder(BaseEstimator,TransformerMixin ):\n",
        "  def __init__(self, add_bedrooms_per_room=True):\n",
        "    self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self,X):\n",
        "    rooms_per_household = X[:, rooms_ix ]\n",
        "    population_per_household = X[:,population_ix]/ X[:,households_ix]\n",
        "    if self.add_bedrooms_per_room:\n",
        "      bedrooms_per_room = X[:,bedrooms_ix] / X[:,rooms_ix]\n",
        "      return np.c_[X, rooms_per_household,population_per_household ,bedrooms_per_room ]\n",
        "\n",
        "    else:\n",
        "      return np.c_[X, rooms_per_household,population_per_household ]\n",
        "\n",
        "attr_adder= CombinedAttributeAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ],
      "metadata": {
        "id": "sSbfbvlctLF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) 두 배열을 왼쪽에서 오른쪽으로 붙이기 \n",
        "\n",
        "   : np.r_[a, b]\n",
        "\n",
        "   : np.hstack([a, b])\n",
        "   : np.concatenate((a, b), axis = 0)\n",
        "\n",
        "\n",
        "\n",
        "(2) 두 배열을 위에서 아래로 붙이기\n",
        "\n",
        "   : np.r_[[a], [b]]\n",
        "\n",
        "   : np.vstack([a, b])\n",
        "\n",
        "   : np.concatenate((c, d), axis = 1) # for 2D ~ array\n",
        "\n",
        "\n",
        "\n",
        "(3) 두 개의 1차원 배열을 칼럼으로 세로로 붙여서 2차원 배열 만들기\n",
        "\n",
        "    (Stack 1-D arrays as columns into a 2-D array)\n",
        "\n",
        "   : np.c_[a, b]\n",
        "\n",
        "   : np.column_stack([a, b])\n",
        "\n",
        "   : np.concatenate((c.T, d.T), axis = 1) # for 2D~ array"
      ],
      "metadata": {
        "id": "ofXimGzcUmRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 특성 스케일링"
      ],
      "metadata": {
        "id": "Im9C2JqxWYQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 특성의 범위를 같도록 만드렁주는 방법 1. min-max 스케일링,2. 표준화\n",
        "\n",
        "1. min-max 스케일링\n",
        "\n",
        "\n",
        " 0-1사이에 들도록 값을 이동하고 스케일을 조정한것\n",
        "\n",
        "데이터에서 최솟값을 뺀 후, 최댓값과 최솟값의 차이로 나누기.\n",
        "\n",
        "2. 표준화\n",
        "\n",
        "\n",
        "먼저 평균을 뺀후, (표준을 하면 평균이 0 - 우리가 아는 정규분포처럼 만드는게 \n",
        "\n",
        "표준화? ) 이는 범위의 상한과 하한이 없어 특정 알고리즘에서는 문제가 될 수 있다.\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "**하지만.. ! 만약 이상치가 존재할 경우에는 표준화가 영향을 덜 받고**\n",
        "\n",
        "**min-max 스케일링은 이상치에 영향을 받기 때문에.. 이상치를 고려해서 이 둘의 스케일링을 선택하도록 해야한다. **\n"
      ],
      "metadata": {
        "id": "xqjJNzXjXaQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 변환 파이프라인"
      ],
      "metadata": {
        "id": "yRs9LPyDYdTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 변환 단계가 많을 경우, 정확한 순서대로 실행되어야함...!\n",
        "\n",
        " 사이킷런의 연속된 변환을 순서대로 처리할 수 있도록 하는  pipeline 클래스 이용\n",
        "\n",
        "**숫자 특성을 처리하는 파이프라인**\n"
      ],
      "metadata": {
        "id": "Wp5eC7s9Y20R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 처음부터 변환을 시도할때 이러한 파이프라인을 사용해서 코딩을 짜면 보다 효율적이고 정확한 순서대로 변환을 처리할 수 있다.\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy = \"median\")),\n",
        "    ('attribs_adder', CombinedAttributeAdder()),\n",
        "    (\"std_scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ],
      "metadata": {
        "id": "Gj_5A2UCYhri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_num_tr"
      ],
      "metadata": {
        "id": "BeeGVjeBogxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ColumnTransformer 등장 / for 사이킷런\n",
        "# 하나의 변환기로 각 열마다 적절한 변환을 적용해 모든 열을 처리할 수 있도록 한다 .\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    ('num', num_pipeline,num_attribs ),\n",
        "    ('cat', OneHotEncoder(), cat_attribs)\n",
        "])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "\n",
        "# num - 밀집 행렬 반환\n",
        "# cat - 희소 행렬 반환"
      ],
      "metadata": {
        "id": "uKtfWvOtahb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_prepared"
      ],
      "metadata": {
        "id": "RRqIVLwPooKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_prepared.shape"
      ],
      "metadata": {
        "id": "h1Z1Y6_HoqqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 선택과 훈련"
      ],
      "metadata": {
        "id": "HlCLYkkzcFmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)\n"
      ],
      "metadata": {
        "id": "1NKLjOmdcHg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_data = housing.iloc[:5]\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "print(\"예측: \",lin_reg.predict(some_data_prepared))\n"
      ],
      "metadata": {
        "id": "gBlc77iGd6VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"레이블: \", list(some_labels))"
      ],
      "metadata": {
        "id": "AtQsRwy1pBv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_data_prepared"
      ],
      "metadata": {
        "id": "xh2Eu9yHpNXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ],
      "metadata": {
        "id": "STuAbmrCgXr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "DCOn_0asiYpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "metadata": {
        "id": "tz64HZ89itIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "오차 존재 x -> 과대적합... ㅎㅎ"
      ],
      "metadata": {
        "id": "FP2BOIhrp2W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차검증을 사용한 평가\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "tree_rmse_scores = np.sqrt(-scores)"
      ],
      "metadata": {
        "id": "WSqS3k6-p2L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_scores(scores):\n",
        "  print(\"점수: \", scores)\n",
        "  print(\"평균: \", scores.mean())\n",
        "  print(\"표준편차: \", scores.std())"
      ],
      "metadata": {
        "id": "WAMJT7RGp8X7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_scores(tree_rmse_scores)"
      ],
      "metadata": {
        "id": "kmCB5cnSs8iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "metadata": {
        "id": "PhKkjvEAtAX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "BNWReli_tWiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing_predictions = forest_reg.predict(housing_prepared)\n",
        "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "forest_rmse"
      ],
      "metadata": {
        "id": "NKR-y2EhvvNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "display_scores(forest_rmse_scores)"
      ],
      "metadata": {
        "id": "D8natTU-tr2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "pd.Series(np.sqrt(-scores)).describe()"
      ],
      "metadata": {
        "id": "rfc8oog3wy9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_reg = SVR(kernel=\"linear\")\n",
        "svm_reg.fit(housing_prepared, housing_labels)\n",
        "housing_predictions = svm_reg.predict(housing_prepared)\n",
        "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "svm_rmse = np.sqrt(svm_mse)\n",
        "svm_rmse"
      ],
      "metadata": {
        "id": "sFBUzGZOw2k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 세부 튜닝"
      ],
      "metadata": {
        "id": "rScZRsOWKD1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그리드 탐색\n",
        "\n",
        "simple method: 만족할 만한 하이퍼파라미터 조합을 찾을때까지 수동으로 조정하는거\n",
        "\n",
        "-> 자동화: 사이킷런의 GridSearchCV사용하기\n",
        "(탐색하고자 하는 하이퍼파라미터와 시도해볼 값을 지정만 하면 가능)"
      ],
      "metadata": {
        "id": "hKc9tXNzKIf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForestRegressor에 대한 최적의 하이퍼파라미터 조합 탐색하기\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    {\"n_estimators\": [3,10,30], \"max_features\": [2,4,6,8]},\n",
        "    {\"bootstrap\":[False], \"n_estimators\":[3,10], \"max_features\": [2,3,4]},\n",
        "]\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring = \"neg_mean_squared_error\",\n",
        "                           return_train_score =True)\n",
        "\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "E42lnoeKKGbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "iUveYMg-LMjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  최적의 추정기에 직접 접근도 가능\n",
        "\n",
        "grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "ZVXepL02LjV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가점수 확인\n",
        "\n",
        "cvres= grid_search.cv_results_\n",
        "\n",
        "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "  print(np.sqrt(-mean_score), params)"
      ],
      "metadata": {
        "id": "VY6nSGpXLvKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "50055.90991344175 {'max_features': 6, 'n_estimators': 30}\n",
        "\n",
        "이 예시에서는 max_features의 하이퍼파리미터가 6, n_estimators의 하이퍼파라미터가 30일때 최적의 솔루션임을 확인가능\n",
        "\n",
        "\n",
        "... 뭔가 잘못되었는뎅ㅂ...ㅎ? "
      ],
      "metadata": {
        "id": "CP0r6JE1MYPw"
      }
    }
  ]
}